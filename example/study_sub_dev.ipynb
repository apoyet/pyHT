{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "#from Job import JobObj\n",
    "\n",
    "class StudyObj():\n",
    "    '''\n",
    "    This class is used to define a study to be submitted to HTCondor. This particularly useful in the case of multiple jobs submissions. \n",
    "    A study will be defined by an executable, a submission file and a set of parameters, corresponding to a single job. Each job is instantiated from the Job class.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, name, executable, submit_file, input_dir = \"\", arguments = \"$(ClusterId) $(ProcId)\", \n",
    "                 output_dir = \"\", error_dir = \"\", log_dir = \"\", job_flavour = \"\", universe = \"vanilla\",\n",
    "                 queue = \"\"):\n",
    "        self.name = name\n",
    "        self.executable = executable\n",
    "        self.submit_file = submit_file\n",
    "        self.input_dir = input_dir\n",
    "        self.arguments = arguments\n",
    "        self.output_dir = output_dir\n",
    "        self.error_dir = error_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.job_flavour = job_flavour\n",
    "        self.universe = universe\n",
    "        self.queue = queue\n",
    "\n",
    "        \n",
    "    def define_study(self, param):\n",
    "        '''\n",
    "        This method will define the list of jobs of the study. It therefore takes as arguments the parameters to vary in the study amongs the different jobs. \n",
    "        'paramaters' is a multi-dimensionnal array containing the values of the different paramaters. \n",
    "\n",
    "        **** EXAMPLE ****\n",
    "        The study is called 'myScan'. And it will scan two parameters Temp and Press from 0 to 10 for Temp and 50 to 60 for Press.\n",
    "\n",
    "        define_study(np.array([[0, 2, 4, 6, 8, 10], [50, 55, 60]]))\n",
    "        >>> ['myScan_0_50', 'myScan_0_55', ...]\n",
    "        '''\n",
    "        myList = []\n",
    "        self.parameters_keys = param.keys()\n",
    "        self.parameters_values = param.values()\n",
    "        self.parameters = param\n",
    "        for a in itertools.product(*self.parameters_values):\n",
    "            myList.append((self.name+'_{}'*len(a)).format(*a))\n",
    "        self.jobs_names = myList\n",
    "        \n",
    "    def get_studyDF(self):\n",
    "        '''\n",
    "        This method creates a pandas Dataframe containg the information of each job to be submitted\n",
    "        '''\n",
    "        # first to get the values of the parameters\n",
    "        myArray = np.zeros([np.prod([len(e) for e in self.parameters_values]), len(self.parameters_keys)])\n",
    "        flag = 0\n",
    "        for a in itertools.product(*self.parameters_values):\n",
    "            myArray[flag] = a\n",
    "            flag+=1\n",
    "        \n",
    "        # df definition\n",
    "        myColumns = [param for param in self.parameters_keys] + ['Input', 'Output', 'Error', 'Log']\n",
    "        myDF = pd.DataFrame(index = self.jobs_names, columns=myColumns)\n",
    "        \n",
    "        # store the parameters values\n",
    "        myDF[[param for param in self.parameters_keys]] = myArray\n",
    "        \n",
    "        # files paths\n",
    "        myDF['ProcID'] = [str(e) for e in range(self.number_jobs)]\n",
    "        myDF['Input'] = self.input_dir + myDF.index + '.in'\n",
    "        myDF['Output'] = self.output_dir + self.name + '.' + str(self.clusterID) + '.' + myDF['ProcID'] + '.out'\n",
    "        myDF['Error'] = self.error_dir + self.name + '.' + str(self.clusterID) + '.' + myDF['ProcID'] + '.err'\n",
    "        myDF['Log'] = self.log_dir + self.name + '.{}.log'.format(self.clusterID)\n",
    "        \n",
    "        return myDF\n",
    "    \n",
    "    def submit2str(self):\n",
    "        '''\n",
    "        This methods creates the string that will be writen in a file afterwards. \n",
    "        '''\n",
    "        \n",
    "        myString = '''executable = {}\\n'''.format(self.executable)\n",
    "        if self.input_dir:\n",
    "            myString += '''input = $(input_file)\\n'''\n",
    "        if self.arguments:\n",
    "            myString += '''arguments = {}\\n'''.format(self.arguments)\n",
    "        if self.output_dir:\n",
    "            myString += '''output = {}.$(ClusterId).$(ProcId).out\\n'''.format(self.output_dir+self.name)\n",
    "        if self.error_dir:\n",
    "            myString += '''error = {}.$(ClusterId).$(ProcId).err\\n'''.format(self.error_dir+self.name)\n",
    "        if self.log_dir:\n",
    "            myString += '''log = {}.$(ClusterId).log\\n'''.format(self.log_dir+self.name)\n",
    "        if self.universe:\n",
    "            myString += '''universe = {}\\n'''.format(self.universe)\n",
    "        if self.job_flavour:\n",
    "            myString += '''+JobFlavour = \"{}\"\\n'''.format(self.job_flavour)\n",
    "            \n",
    "        myString += '''queue input_file matching files input/{}_*.in'''.format(self.name)\n",
    "        return myString\n",
    "    \n",
    "    \n",
    "    def submit2file(self, string):\n",
    "        submit_file = open(self.submit_file, \"w\")\n",
    "        submit_file.write(string)\n",
    "        submit_file.close()\n",
    "        \n",
    "    def display_subfile(self):\n",
    "        f = open(self.submit_file, 'r')\n",
    "        text = f.read()\n",
    "        print(text)\n",
    "        \n",
    "    def submit2HTCondor(self):\n",
    "        myString = subprocess.check_output([\"condor_submit\", self.submit_file])\n",
    "        print(myString)\n",
    "        myString = myString[:-2]\n",
    "        count = [int(s) for s in myString.split() if s.isdigit()]\n",
    "        self.number_jobs = count[0]\n",
    "        self.clusterID = count[1]\n",
    "        \n",
    "    def condor_q(self, nobatch=False, jobID=None):\n",
    "        if nobatch: \n",
    "            print(subprocess.check_output([\"condor_q\",\"-nobatch\"]))\n",
    "        elif jobID: \n",
    "            print(subprocess.check_output([\"condor_q\", jobID]))\n",
    "        else: \n",
    "            print(subprocess.check_output([\"condor_q\"]))\n",
    "            \n",
    "    def describe_study(self, attributes=\"\"):\n",
    "        '''\n",
    "        This methods displays all or part of the attributes of the study. \n",
    "        To display part of \n",
    "        '''\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "myParam = {'temp' : [10], 'press' : [1,2], 'I' : [5], 'wind' : [5, 2, 1, 9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d3764fbf0da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/afs/cern.ch/work/a/apoyet/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    328\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cern.ch/work/a/apoyet/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cern.ch/work/a/apoyet/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   6161\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6163\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6164\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6165\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cern.ch/work/a/apoyet/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   6209\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6211\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(myParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the study \n",
    "\n",
    "myStudy = StudyObj('myStudy', '/afs/cern.ch/user/m/mad/bin/madx', 'mySubFile', input_dir='input/', output_dir='output/', error_dir='error/',\n",
    "                   log_dir = 'log/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the parameters\n",
    "# NB : the number of parameters doesn't matter\n",
    "\n",
    "myStudy.define_study(temp = [10], press = [1,2], I = [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters are : ['press', 'I', 'wind', 'temp']\n",
      "Their values are : [[1, 2], [5], [5, 2, 1, 9], [10]]\n",
      "Printing in full : {'press': [1, 2], 'I': [5], 'wind': [5, 2, 1, 9], 'temp': [10]}\n"
     ]
    }
   ],
   "source": [
    "# One can access the parameters and their values\n",
    "\n",
    "print('The parameters are : {}'.format(myStudy.parameters_keys))\n",
    "print('Their values are : {}'.format(myStudy.parameters_values))\n",
    "print('Printing in full : {}'.format(myStudy.parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the submission file corresponding to the STUDY \n",
    "# NB : MULTIPLE JOBS SUBMISSION\n",
    "\n",
    "myStudy.submit2file(myStudy.submit2str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executable = /afs/cern.ch/user/m/mad/bin/madx\n",
      "input = $(input_file)\n",
      "arguments = $(ClusterId) $(ProcId)\n",
      "output = output/myStudy.$(ClusterId).$(ProcId).out\n",
      "error = error/myStudy.$(ClusterId).$(ProcId).err\n",
      "log = log/myStudy.$(ClusterId).log\n",
      "universe = vanilla\n",
      "queue input_file matching files input/myStudy_*.in\n"
     ]
    }
   ],
   "source": [
    "# One can display the submission file\n",
    "\n",
    "myStudy.display_subfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job(s)..\n",
      "2 job(s) submitted to cluster 3578456.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And...... SUBMISSION\n",
    "\n",
    "myStudy.submit2HTCondor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- Schedd: bigbird16.cern.ch : <188.184.90.62:9618?... @ 06/25/19 14:15:26\n",
      "OWNER  BATCH_NAME    SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS\n",
      "apoyet CMD: madx    6/25 14:15      _      _      2      2 3578456.0-1\n",
      "\n",
      "2 jobs; 0 completed, 0 removed, 2 idle, 0 running, 0 held, 0 suspended\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myStudy.condor_q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea then is to generate a pandas DataFrame containing the different points (or JOBS) of the study\n",
    "# The DF will be used as a reference afterwards to retrieve which job was made which which parameters\n",
    "# It should therefore contains the paths of the corresponding files\n",
    "\n",
    "df = myStudy.get_studyDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>press</th>\n",
       "      <th>I</th>\n",
       "      <th>temp</th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "      <th>Error</th>\n",
       "      <th>Log</th>\n",
       "      <th>ProcID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>myStudy_1_5_10</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>input/myStudy_1_5_10.in</td>\n",
       "      <td>output/myStudy.3578456.0.out</td>\n",
       "      <td>error/myStudy.3578456.0.err</td>\n",
       "      <td>log/myStudy.3578456.log</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myStudy_2_5_10</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>input/myStudy_2_5_10.in</td>\n",
       "      <td>output/myStudy.3578456.1.out</td>\n",
       "      <td>error/myStudy.3578456.1.err</td>\n",
       "      <td>log/myStudy.3578456.log</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               press  I temp                    Input  \\\n",
       "myStudy_1_5_10     1  5   10  input/myStudy_1_5_10.in   \n",
       "myStudy_2_5_10     2  5   10  input/myStudy_2_5_10.in   \n",
       "\n",
       "                                      Output                        Error  \\\n",
       "myStudy_1_5_10  output/myStudy.3578456.0.out  error/myStudy.3578456.0.err   \n",
       "myStudy_2_5_10  output/myStudy.3578456.1.out  error/myStudy.3578456.1.err   \n",
       "\n",
       "                                    Log ProcID  \n",
       "myStudy_1_5_10  log/myStudy.3578456.log      0  \n",
       "myStudy_2_5_10  log/myStudy.3578456.log      1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ProcID']['myStudy_1_5_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = subprocess.check_output([\"echo\", \"2 job(s) submitted to cluster 3574985.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test'] = 'nandgw_frqeg'+df['ProcID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myStudy_1_5_10    nandgw_frqeg0\n",
       "myStudy_2_5_10    nandgw_frqeg1\n",
       "Name: test, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['myStudy_1_5_5_10', 'myStudy_1_5_2_10', 'myStudy_1_5_1_10', 'myStudy_1_5_9_10', 'myStudy_2_5_5_10', 'myStudy_2_5_2_10', 'myStudy_2_5_1_10', 'myStudy_2_5_9_10']\n"
     ]
    }
   ],
   "source": [
    "print(myStudy.jobs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '$(ClusterId) $(ProcId)',\n",
       " 'error_dir': 'error/',\n",
       " 'executable': '/afs/cern.ch/user/m/mad/bin/madx',\n",
       " 'input_dir': 'input/',\n",
       " 'job_flavour': '',\n",
       " 'jobs_names': ['myStudy_1_5_5_10',\n",
       "  'myStudy_1_5_2_10',\n",
       "  'myStudy_1_5_1_10',\n",
       "  'myStudy_1_5_9_10',\n",
       "  'myStudy_2_5_5_10',\n",
       "  'myStudy_2_5_2_10',\n",
       "  'myStudy_2_5_1_10',\n",
       "  'myStudy_2_5_9_10'],\n",
       " 'log_dir': 'log/',\n",
       " 'name': 'myStudy',\n",
       " 'output_dir': 'output/',\n",
       " 'parameters': {'I': [5], 'press': [1, 2], 'temp': [10], 'wind': [5, 2, 1, 9]},\n",
       " 'parameters_keys': ['press', 'I', 'wind', 'temp'],\n",
       " 'parameters_values': [[1, 2], [5], [5, 2, 1, 9], [10]],\n",
       " 'queue': '',\n",
       " 'submit_file': 'mySubFile',\n",
       " 'universe': 'vanilla'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(myStudy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$(ClusterId) $(ProcId)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictfilt = lambda x, y: dict([ (i,x[i]) for i in x if i in set(y) ])\n",
    "\n",
    "myStudy.__dict__['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
